{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import lightning as L\n",
    "\n",
    "from model.modeling_demolta import DeMOLTaConfig\n",
    "from trainer import LitMOLLAForRegression, LitDeMOLTaForRegression, SaveTrainableParamsCheckpoint\n",
    "from datautils import LitMOLLAFineTuneDataModule, LitDeMOLTaFineTuneDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "SEED = 42\n",
    "TEXT_MODEL_NAME = './Llama-2-7b-hf'\n",
    "# TEXT_MODEL_NAME = 'meta-llama/Llama-2-7b-hf'\n",
    "# HF_ACCESS_TOKEN = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_finetune_data_module = LitDeMOLTaFineTuneDataModule(\n",
    "    df_path='./data/train.csv',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    k_fold=5,\n",
    "    train_fold=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demolta_config = DeMOLTaConfig(\n",
    "    num_layers=12,\n",
    "    node_hidden_dim=768,\n",
    "    edge_hidden_dim=256,\n",
    "    node_ff_dim=3072,\n",
    "    edge_ff_dim=1536,\n",
    "    num_heads=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitMOLLAForRegression(\n",
    "    demolta_config=demolta_config,\n",
    "    text_model_name=TEXT_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_finetune_data_module = LitMOLLAFineTuneDataModule(\n",
    "    df_path='./data/train.csv',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    query = 'What is the LC-MS/MS percentage value of the molecule after reacting with MLM (Mouse Liver Microsome) for 30 minutes?',\n",
    "    column_name='MLM',\n",
    "    tokenizer_name = TEXT_MODEL_NAME,\n",
    "    seed=SEED,\n",
    "    k_fold=5,\n",
    "    train_fold=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "demolta_config = DeMOLTaConfig(\n",
    "    num_layers=12,\n",
    "    node_hidden_dim=768,\n",
    "    edge_hidden_dim=256,\n",
    "    node_ff_dim=3072,\n",
    "    edge_ff_dim=1536,\n",
    "    num_heads=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7bee337b6d464e8a35d50c679e267b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "lit_model = LitMOLLAForRegression(\n",
    "    demolta_config=demolta_config,\n",
    "    text_model_name=TEXT_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['model.language_model.model.embed_tokens.weight', 'model.language_model.model.layers.0.self_attn.q_proj.weight', 'model.language_model.model.layers.0.self_attn.k_proj.weight', 'model.language_model.model.layers.0.self_attn.v_proj.weight', 'model.language_model.model.layers.0.self_attn.o_proj.weight', 'model.language_model.model.layers.0.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.0.mlp.gate_proj.weight', 'model.language_model.model.layers.0.mlp.down_proj.weight', 'model.language_model.model.layers.0.mlp.up_proj.weight', 'model.language_model.model.layers.0.input_layernorm.weight', 'model.language_model.model.layers.0.post_attention_layernorm.weight', 'model.language_model.model.layers.1.self_attn.q_proj.weight', 'model.language_model.model.layers.1.self_attn.k_proj.weight', 'model.language_model.model.layers.1.self_attn.v_proj.weight', 'model.language_model.model.layers.1.self_attn.o_proj.weight', 'model.language_model.model.layers.1.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.1.mlp.gate_proj.weight', 'model.language_model.model.layers.1.mlp.down_proj.weight', 'model.language_model.model.layers.1.mlp.up_proj.weight', 'model.language_model.model.layers.1.input_layernorm.weight', 'model.language_model.model.layers.1.post_attention_layernorm.weight', 'model.language_model.model.layers.2.self_attn.q_proj.weight', 'model.language_model.model.layers.2.self_attn.k_proj.weight', 'model.language_model.model.layers.2.self_attn.v_proj.weight', 'model.language_model.model.layers.2.self_attn.o_proj.weight', 'model.language_model.model.layers.2.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.2.mlp.gate_proj.weight', 'model.language_model.model.layers.2.mlp.down_proj.weight', 'model.language_model.model.layers.2.mlp.up_proj.weight', 'model.language_model.model.layers.2.input_layernorm.weight', 'model.language_model.model.layers.2.post_attention_layernorm.weight', 'model.language_model.model.layers.3.self_attn.q_proj.weight', 'model.language_model.model.layers.3.self_attn.k_proj.weight', 'model.language_model.model.layers.3.self_attn.v_proj.weight', 'model.language_model.model.layers.3.self_attn.o_proj.weight', 'model.language_model.model.layers.3.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.3.mlp.gate_proj.weight', 'model.language_model.model.layers.3.mlp.down_proj.weight', 'model.language_model.model.layers.3.mlp.up_proj.weight', 'model.language_model.model.layers.3.input_layernorm.weight', 'model.language_model.model.layers.3.post_attention_layernorm.weight', 'model.language_model.model.layers.4.self_attn.q_proj.weight', 'model.language_model.model.layers.4.self_attn.k_proj.weight', 'model.language_model.model.layers.4.self_attn.v_proj.weight', 'model.language_model.model.layers.4.self_attn.o_proj.weight', 'model.language_model.model.layers.4.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.4.mlp.gate_proj.weight', 'model.language_model.model.layers.4.mlp.down_proj.weight', 'model.language_model.model.layers.4.mlp.up_proj.weight', 'model.language_model.model.layers.4.input_layernorm.weight', 'model.language_model.model.layers.4.post_attention_layernorm.weight', 'model.language_model.model.layers.5.self_attn.q_proj.weight', 'model.language_model.model.layers.5.self_attn.k_proj.weight', 'model.language_model.model.layers.5.self_attn.v_proj.weight', 'model.language_model.model.layers.5.self_attn.o_proj.weight', 'model.language_model.model.layers.5.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.5.mlp.gate_proj.weight', 'model.language_model.model.layers.5.mlp.down_proj.weight', 'model.language_model.model.layers.5.mlp.up_proj.weight', 'model.language_model.model.layers.5.input_layernorm.weight', 'model.language_model.model.layers.5.post_attention_layernorm.weight', 'model.language_model.model.layers.6.self_attn.q_proj.weight', 'model.language_model.model.layers.6.self_attn.k_proj.weight', 'model.language_model.model.layers.6.self_attn.v_proj.weight', 'model.language_model.model.layers.6.self_attn.o_proj.weight', 'model.language_model.model.layers.6.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.6.mlp.gate_proj.weight', 'model.language_model.model.layers.6.mlp.down_proj.weight', 'model.language_model.model.layers.6.mlp.up_proj.weight', 'model.language_model.model.layers.6.input_layernorm.weight', 'model.language_model.model.layers.6.post_attention_layernorm.weight', 'model.language_model.model.layers.7.self_attn.q_proj.weight', 'model.language_model.model.layers.7.self_attn.k_proj.weight', 'model.language_model.model.layers.7.self_attn.v_proj.weight', 'model.language_model.model.layers.7.self_attn.o_proj.weight', 'model.language_model.model.layers.7.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.7.mlp.gate_proj.weight', 'model.language_model.model.layers.7.mlp.down_proj.weight', 'model.language_model.model.layers.7.mlp.up_proj.weight', 'model.language_model.model.layers.7.input_layernorm.weight', 'model.language_model.model.layers.7.post_attention_layernorm.weight', 'model.language_model.model.layers.8.self_attn.q_proj.weight', 'model.language_model.model.layers.8.self_attn.k_proj.weight', 'model.language_model.model.layers.8.self_attn.v_proj.weight', 'model.language_model.model.layers.8.self_attn.o_proj.weight', 'model.language_model.model.layers.8.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.8.mlp.gate_proj.weight', 'model.language_model.model.layers.8.mlp.down_proj.weight', 'model.language_model.model.layers.8.mlp.up_proj.weight', 'model.language_model.model.layers.8.input_layernorm.weight', 'model.language_model.model.layers.8.post_attention_layernorm.weight', 'model.language_model.model.layers.9.self_attn.q_proj.weight', 'model.language_model.model.layers.9.self_attn.k_proj.weight', 'model.language_model.model.layers.9.self_attn.v_proj.weight', 'model.language_model.model.layers.9.self_attn.o_proj.weight', 'model.language_model.model.layers.9.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.9.mlp.gate_proj.weight', 'model.language_model.model.layers.9.mlp.down_proj.weight', 'model.language_model.model.layers.9.mlp.up_proj.weight', 'model.language_model.model.layers.9.input_layernorm.weight', 'model.language_model.model.layers.9.post_attention_layernorm.weight', 'model.language_model.model.layers.10.self_attn.q_proj.weight', 'model.language_model.model.layers.10.self_attn.k_proj.weight', 'model.language_model.model.layers.10.self_attn.v_proj.weight', 'model.language_model.model.layers.10.self_attn.o_proj.weight', 'model.language_model.model.layers.10.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.10.mlp.gate_proj.weight', 'model.language_model.model.layers.10.mlp.down_proj.weight', 'model.language_model.model.layers.10.mlp.up_proj.weight', 'model.language_model.model.layers.10.input_layernorm.weight', 'model.language_model.model.layers.10.post_attention_layernorm.weight', 'model.language_model.model.layers.11.self_attn.q_proj.weight', 'model.language_model.model.layers.11.self_attn.k_proj.weight', 'model.language_model.model.layers.11.self_attn.v_proj.weight', 'model.language_model.model.layers.11.self_attn.o_proj.weight', 'model.language_model.model.layers.11.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.11.mlp.gate_proj.weight', 'model.language_model.model.layers.11.mlp.down_proj.weight', 'model.language_model.model.layers.11.mlp.up_proj.weight', 'model.language_model.model.layers.11.input_layernorm.weight', 'model.language_model.model.layers.11.post_attention_layernorm.weight', 'model.language_model.model.layers.12.self_attn.q_proj.weight', 'model.language_model.model.layers.12.self_attn.k_proj.weight', 'model.language_model.model.layers.12.self_attn.v_proj.weight', 'model.language_model.model.layers.12.self_attn.o_proj.weight', 'model.language_model.model.layers.12.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.12.mlp.gate_proj.weight', 'model.language_model.model.layers.12.mlp.down_proj.weight', 'model.language_model.model.layers.12.mlp.up_proj.weight', 'model.language_model.model.layers.12.input_layernorm.weight', 'model.language_model.model.layers.12.post_attention_layernorm.weight', 'model.language_model.model.layers.13.self_attn.q_proj.weight', 'model.language_model.model.layers.13.self_attn.k_proj.weight', 'model.language_model.model.layers.13.self_attn.v_proj.weight', 'model.language_model.model.layers.13.self_attn.o_proj.weight', 'model.language_model.model.layers.13.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.13.mlp.gate_proj.weight', 'model.language_model.model.layers.13.mlp.down_proj.weight', 'model.language_model.model.layers.13.mlp.up_proj.weight', 'model.language_model.model.layers.13.input_layernorm.weight', 'model.language_model.model.layers.13.post_attention_layernorm.weight', 'model.language_model.model.layers.14.self_attn.q_proj.weight', 'model.language_model.model.layers.14.self_attn.k_proj.weight', 'model.language_model.model.layers.14.self_attn.v_proj.weight', 'model.language_model.model.layers.14.self_attn.o_proj.weight', 'model.language_model.model.layers.14.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.14.mlp.gate_proj.weight', 'model.language_model.model.layers.14.mlp.down_proj.weight', 'model.language_model.model.layers.14.mlp.up_proj.weight', 'model.language_model.model.layers.14.input_layernorm.weight', 'model.language_model.model.layers.14.post_attention_layernorm.weight', 'model.language_model.model.layers.15.self_attn.q_proj.weight', 'model.language_model.model.layers.15.self_attn.k_proj.weight', 'model.language_model.model.layers.15.self_attn.v_proj.weight', 'model.language_model.model.layers.15.self_attn.o_proj.weight', 'model.language_model.model.layers.15.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.15.mlp.gate_proj.weight', 'model.language_model.model.layers.15.mlp.down_proj.weight', 'model.language_model.model.layers.15.mlp.up_proj.weight', 'model.language_model.model.layers.15.input_layernorm.weight', 'model.language_model.model.layers.15.post_attention_layernorm.weight', 'model.language_model.model.layers.16.self_attn.q_proj.weight', 'model.language_model.model.layers.16.self_attn.k_proj.weight', 'model.language_model.model.layers.16.self_attn.v_proj.weight', 'model.language_model.model.layers.16.self_attn.o_proj.weight', 'model.language_model.model.layers.16.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.16.mlp.gate_proj.weight', 'model.language_model.model.layers.16.mlp.down_proj.weight', 'model.language_model.model.layers.16.mlp.up_proj.weight', 'model.language_model.model.layers.16.input_layernorm.weight', 'model.language_model.model.layers.16.post_attention_layernorm.weight', 'model.language_model.model.layers.17.self_attn.q_proj.weight', 'model.language_model.model.layers.17.self_attn.k_proj.weight', 'model.language_model.model.layers.17.self_attn.v_proj.weight', 'model.language_model.model.layers.17.self_attn.o_proj.weight', 'model.language_model.model.layers.17.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.17.mlp.gate_proj.weight', 'model.language_model.model.layers.17.mlp.down_proj.weight', 'model.language_model.model.layers.17.mlp.up_proj.weight', 'model.language_model.model.layers.17.input_layernorm.weight', 'model.language_model.model.layers.17.post_attention_layernorm.weight', 'model.language_model.model.layers.18.self_attn.q_proj.weight', 'model.language_model.model.layers.18.self_attn.k_proj.weight', 'model.language_model.model.layers.18.self_attn.v_proj.weight', 'model.language_model.model.layers.18.self_attn.o_proj.weight', 'model.language_model.model.layers.18.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.18.mlp.gate_proj.weight', 'model.language_model.model.layers.18.mlp.down_proj.weight', 'model.language_model.model.layers.18.mlp.up_proj.weight', 'model.language_model.model.layers.18.input_layernorm.weight', 'model.language_model.model.layers.18.post_attention_layernorm.weight', 'model.language_model.model.layers.19.self_attn.q_proj.weight', 'model.language_model.model.layers.19.self_attn.k_proj.weight', 'model.language_model.model.layers.19.self_attn.v_proj.weight', 'model.language_model.model.layers.19.self_attn.o_proj.weight', 'model.language_model.model.layers.19.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.19.mlp.gate_proj.weight', 'model.language_model.model.layers.19.mlp.down_proj.weight', 'model.language_model.model.layers.19.mlp.up_proj.weight', 'model.language_model.model.layers.19.input_layernorm.weight', 'model.language_model.model.layers.19.post_attention_layernorm.weight', 'model.language_model.model.layers.20.self_attn.q_proj.weight', 'model.language_model.model.layers.20.self_attn.k_proj.weight', 'model.language_model.model.layers.20.self_attn.v_proj.weight', 'model.language_model.model.layers.20.self_attn.o_proj.weight', 'model.language_model.model.layers.20.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.20.mlp.gate_proj.weight', 'model.language_model.model.layers.20.mlp.down_proj.weight', 'model.language_model.model.layers.20.mlp.up_proj.weight', 'model.language_model.model.layers.20.input_layernorm.weight', 'model.language_model.model.layers.20.post_attention_layernorm.weight', 'model.language_model.model.layers.21.self_attn.q_proj.weight', 'model.language_model.model.layers.21.self_attn.k_proj.weight', 'model.language_model.model.layers.21.self_attn.v_proj.weight', 'model.language_model.model.layers.21.self_attn.o_proj.weight', 'model.language_model.model.layers.21.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.21.mlp.gate_proj.weight', 'model.language_model.model.layers.21.mlp.down_proj.weight', 'model.language_model.model.layers.21.mlp.up_proj.weight', 'model.language_model.model.layers.21.input_layernorm.weight', 'model.language_model.model.layers.21.post_attention_layernorm.weight', 'model.language_model.model.layers.22.self_attn.q_proj.weight', 'model.language_model.model.layers.22.self_attn.k_proj.weight', 'model.language_model.model.layers.22.self_attn.v_proj.weight', 'model.language_model.model.layers.22.self_attn.o_proj.weight', 'model.language_model.model.layers.22.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.22.mlp.gate_proj.weight', 'model.language_model.model.layers.22.mlp.down_proj.weight', 'model.language_model.model.layers.22.mlp.up_proj.weight', 'model.language_model.model.layers.22.input_layernorm.weight', 'model.language_model.model.layers.22.post_attention_layernorm.weight', 'model.language_model.model.layers.23.self_attn.q_proj.weight', 'model.language_model.model.layers.23.self_attn.k_proj.weight', 'model.language_model.model.layers.23.self_attn.v_proj.weight', 'model.language_model.model.layers.23.self_attn.o_proj.weight', 'model.language_model.model.layers.23.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.23.mlp.gate_proj.weight', 'model.language_model.model.layers.23.mlp.down_proj.weight', 'model.language_model.model.layers.23.mlp.up_proj.weight', 'model.language_model.model.layers.23.input_layernorm.weight', 'model.language_model.model.layers.23.post_attention_layernorm.weight', 'model.language_model.model.layers.24.self_attn.q_proj.weight', 'model.language_model.model.layers.24.self_attn.k_proj.weight', 'model.language_model.model.layers.24.self_attn.v_proj.weight', 'model.language_model.model.layers.24.self_attn.o_proj.weight', 'model.language_model.model.layers.24.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.24.mlp.gate_proj.weight', 'model.language_model.model.layers.24.mlp.down_proj.weight', 'model.language_model.model.layers.24.mlp.up_proj.weight', 'model.language_model.model.layers.24.input_layernorm.weight', 'model.language_model.model.layers.24.post_attention_layernorm.weight', 'model.language_model.model.layers.25.self_attn.q_proj.weight', 'model.language_model.model.layers.25.self_attn.k_proj.weight', 'model.language_model.model.layers.25.self_attn.v_proj.weight', 'model.language_model.model.layers.25.self_attn.o_proj.weight', 'model.language_model.model.layers.25.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.25.mlp.gate_proj.weight', 'model.language_model.model.layers.25.mlp.down_proj.weight', 'model.language_model.model.layers.25.mlp.up_proj.weight', 'model.language_model.model.layers.25.input_layernorm.weight', 'model.language_model.model.layers.25.post_attention_layernorm.weight', 'model.language_model.model.layers.26.self_attn.q_proj.weight', 'model.language_model.model.layers.26.self_attn.k_proj.weight', 'model.language_model.model.layers.26.self_attn.v_proj.weight', 'model.language_model.model.layers.26.self_attn.o_proj.weight', 'model.language_model.model.layers.26.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.26.mlp.gate_proj.weight', 'model.language_model.model.layers.26.mlp.down_proj.weight', 'model.language_model.model.layers.26.mlp.up_proj.weight', 'model.language_model.model.layers.26.input_layernorm.weight', 'model.language_model.model.layers.26.post_attention_layernorm.weight', 'model.language_model.model.layers.27.self_attn.q_proj.weight', 'model.language_model.model.layers.27.self_attn.k_proj.weight', 'model.language_model.model.layers.27.self_attn.v_proj.weight', 'model.language_model.model.layers.27.self_attn.o_proj.weight', 'model.language_model.model.layers.27.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.27.mlp.gate_proj.weight', 'model.language_model.model.layers.27.mlp.down_proj.weight', 'model.language_model.model.layers.27.mlp.up_proj.weight', 'model.language_model.model.layers.27.input_layernorm.weight', 'model.language_model.model.layers.27.post_attention_layernorm.weight', 'model.language_model.model.layers.28.self_attn.q_proj.weight', 'model.language_model.model.layers.28.self_attn.k_proj.weight', 'model.language_model.model.layers.28.self_attn.v_proj.weight', 'model.language_model.model.layers.28.self_attn.o_proj.weight', 'model.language_model.model.layers.28.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.28.mlp.gate_proj.weight', 'model.language_model.model.layers.28.mlp.down_proj.weight', 'model.language_model.model.layers.28.mlp.up_proj.weight', 'model.language_model.model.layers.28.input_layernorm.weight', 'model.language_model.model.layers.28.post_attention_layernorm.weight', 'model.language_model.model.layers.29.self_attn.q_proj.weight', 'model.language_model.model.layers.29.self_attn.k_proj.weight', 'model.language_model.model.layers.29.self_attn.v_proj.weight', 'model.language_model.model.layers.29.self_attn.o_proj.weight', 'model.language_model.model.layers.29.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.29.mlp.gate_proj.weight', 'model.language_model.model.layers.29.mlp.down_proj.weight', 'model.language_model.model.layers.29.mlp.up_proj.weight', 'model.language_model.model.layers.29.input_layernorm.weight', 'model.language_model.model.layers.29.post_attention_layernorm.weight', 'model.language_model.model.layers.30.self_attn.q_proj.weight', 'model.language_model.model.layers.30.self_attn.k_proj.weight', 'model.language_model.model.layers.30.self_attn.v_proj.weight', 'model.language_model.model.layers.30.self_attn.o_proj.weight', 'model.language_model.model.layers.30.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.30.mlp.gate_proj.weight', 'model.language_model.model.layers.30.mlp.down_proj.weight', 'model.language_model.model.layers.30.mlp.up_proj.weight', 'model.language_model.model.layers.30.input_layernorm.weight', 'model.language_model.model.layers.30.post_attention_layernorm.weight', 'model.language_model.model.layers.31.self_attn.q_proj.weight', 'model.language_model.model.layers.31.self_attn.k_proj.weight', 'model.language_model.model.layers.31.self_attn.v_proj.weight', 'model.language_model.model.layers.31.self_attn.o_proj.weight', 'model.language_model.model.layers.31.self_attn.rotary_emb.inv_freq', 'model.language_model.model.layers.31.mlp.gate_proj.weight', 'model.language_model.model.layers.31.mlp.down_proj.weight', 'model.language_model.model.layers.31.mlp.up_proj.weight', 'model.language_model.model.layers.31.input_layernorm.weight', 'model.language_model.model.layers.31.post_attention_layernorm.weight', 'model.language_model.model.norm.weight', 'model.language_model.lm_head.weight', 'model.regressor.0.weight', 'model.regressor.0.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./checkpoints/mola-pretrain-base-Llama-2-7b-hf-step=60000-train_loss=2.1271-val_loss=2.60.ckpt')\n",
    "lit_model.load_state_dict(checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in lit_model.model.mol_model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = SaveTrainableParamsCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./checkpoints/',\n",
    "    filename='molla-llama2-pretrain=60000-finetune-{epoch}-{val_loss:.4f}',\n",
    "    save_top_k=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator='gpu',\n",
    "    max_epochs=10,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    val_check_interval=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "c:\\Users\\dust\\Documents\\Dacon\\med\\demolta\\datautils.py:142: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df = df.groupby('SMILES').mean().reset_index()\n",
      "c:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:615: UserWarning: Checkpoint directory C:\\Users\\dust\\Documents\\Dacon\\med\\demolta\\checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 8.00 GiB total capacity; 7.25 GiB already allocated; 0 bytes free; 7.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(lit_model, lit_finetune_data_module)\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:529\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    527\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    528\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[1;32m--> 529\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    530\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    531\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     44\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:568\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[0;32m    559\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[0;32m    560\u001b[0m )\n\u001b[0;32m    562\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    563\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    564\u001b[0m     ckpt_path,\n\u001b[0;32m    565\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    566\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    567\u001b[0m )\n\u001b[1;32m--> 568\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    570\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    571\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:949\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mreset_metrics()\n\u001b[0;32m    948\u001b[0m \u001b[39m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[1;32m--> 949\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49msetup(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    951\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\lightning\\pytorch\\strategies\\single_device.py:74\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[1;34m(self, trainer)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup\u001b[39m(\u001b[39mself\u001b[39m, trainer: pl\u001b[39m.\u001b[39mTrainer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_to_device()\n\u001b[0;32m     75\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msetup(trainer)\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\lightning\\pytorch\\strategies\\single_device.py:71\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.model_to_device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_to_device\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mself.model must be set before self.model.to()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 71\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot_device)\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\lightning\\fabric\\utilities\\device_dtype_mixin.py:54\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m device, dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39m_parse_to(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)[:\u001b[39m2\u001b[39m]\n\u001b[0;32m     53\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__update_properties(device\u001b[39m=\u001b[39mdevice, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mto(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 797 (4 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\dust\\anaconda3\\envs\\py310_torch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 8.00 GiB total capacity; 7.25 GiB already allocated; 0 bytes free; 7.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.fit(lit_model, lit_finetune_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
